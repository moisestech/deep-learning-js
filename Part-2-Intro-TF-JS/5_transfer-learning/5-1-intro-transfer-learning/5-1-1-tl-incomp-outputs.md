# ðŸŸ¦ TL Incomp Outputs

## [**5.1.1.** Transfer learning based on compatible output shapes: Freezing layers](https://livebook.manning.com/book/deep-learning-with-javascript/chapter-5/20)

---

### [**Figure 5.2.** A printed summary of the convnet for recognition of MNIST images and transfer learning](https://livebook.manning.com/book/deep-learning-with-javascript/chapter-5/ch05fig02)

<img src="../../../assets/figures/Figure_5-2.png">

### [**Figure 5.3.** The loss and validation curves for transfer learning on the MNIST convnet.](https://livebook.manning.com/book/deep-learning-with-javascript/chapter-5/ch05fig03)

<img src="../../../assets/figures/Figure_5-3.png">

### [**Figure 5.4.** A schematic explanation for why freezing some layers of a model speeds up training.](https://livebook.manning.com/book/deep-learning-with-javascript/chapter-5/ch05fig04)

<img src="../../../assets/figures/Figure_5-4.png">

---

## **Vocabulary**

- **compatible output shapes**
- **freezing layers**
- **activation function**
- **softmax**
- **`retrainModel()`**
- **trainable**
- **optimizer**
- **untrainable**
- **flatten layer**
- **`trainable`**
- **`fit()`**
- **predictions**
- **gradients**
- **backpropagation**
- **layer-freezing approach**

---

from [[_5-1-intro-tl]]

[//begin]: # "Autogenerated link references for markdown compatibility"
[_5-1-intro-tl]: _5-1-intro-tl.md "ðŸŸ¦ Intro TL"
[//end]: # "Autogenerated link references"
