# ♒️ Hyper Param Optim

## [**3.1.2.** Hyperparameters and hyperparameter optimization](https://livebook.manning.com/book/deep-learning-with-javascript/chapter-3/67)

- [Initializing neural networks](https://www.deeplearning.ai/ai-notes/initialization/)

---

## **Vocabulary**

- **`leCunNormal`**
  - these initializations produce weights that are **randomly selected numbers** multiplied with the **variance 1/fan-in**.
- **`'glorotNormal'`**
  - in this approach, each randomly generated weight is multiplied by variance 2/(fan-in + fan-out).
  - For a theoretical justification of the Xavier initialization, you can refer to the deeplearning.ai post on Initialization.
- **model quality**
  - Quality is comprised of consistency and accuracy. It is not just how correct a label is, but also how often it is correct.
  - This section describes the industry standard methods for measuring consistency and accuracy.
- **hyperparameters**
- **`Model.fit()`**
- **units**
- **kernelInitializer**
- **optimizer**
- **`Model.compile()`**
- **weight regularization** - is any technique that aims to improve the validation score, sometimes at the cost of reducing the training score.
- **dropout layers** - is a technique applied to neural networks that randomly sets some of the neurons’ outputs to zero during training. This forces the network to learn better representations of the data by preventing complex interactions between the neurons: Each neuron needs to learn useful features.
- **L1 regularization** - tries to minimize the absolute value of the parameters of the model. It produces sparse parameters.
- **L2 regularization** - tries to minimize the square value of the parameters of the model. It produces parameters with small values.
- **`'sgd'` vs `'adam'`**
- **hyperparameter optimization**
- **hyperparameter tuning**
- **algorithm**
- **categorical parameter**
- **regularization factors**
- **gradient descent**

## **Blog**

- [How to Measure Quality when Training Machine Learning Model](https://hackernoon.com/how-to-measure-quality-when-training-machine-learning-models-cc9196dd377a)

---

from [[_3_adding-non-linearity]]

[//begin]: # "Autogenerated link references for markdown compatibility"
[_3_adding-non-linearity]: ../_3_adding-non-linearity.md "♒️ NON-LINEARITY"
[//end]: # "Autogenerated link references"
