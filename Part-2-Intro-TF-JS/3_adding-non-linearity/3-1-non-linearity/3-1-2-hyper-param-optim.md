# ♒️ Hyper Param Optim

## [**3.1.2.** Hyperparameters and hyperparameter optimization](https://livebook.manning.com/book/deep-learning-with-javascript/chapter-3/67)

- [Initializing neural networks](https://www.deeplearning.ai/ai-notes/initialization/)

---

## **Vocabulary**

- **`leCunNormal`** - these initializations produce weights that are **randomly selected numbers** multiplied with the **variance 1/fan-in**.
- **`'glorotNormal'`** - in this approach, each randomly generated weight is multiplied by variance 2/(fan-in + fan-out).
  - For a theoretical justification of the Xavier initialization, you can refer to the deeplearning.ai post on Initialization.
- **model quality** - Quality is comprised of consistency and accuracy. It is not just how correct a label is, but also how often it is correct.
  - This section describes the industry standard methods for measuring consistency and accuracy.
- **hyperparameters** -
- **`Model.fit()`** -
- **units** -
- **kernelInitializer** -
- **optimizer** -
- **`Model.compile()`** -
- **weight regularization** -
- **dropout layers** -
- **`'sgd'` vs `'adam'`** -
- **hyperparameter optimization** -
- **hyperparameter tuning** -
- **algorithm** -
- **categorical parameter** -
- **regularization factors** -
- **gradient descent** -

## **Blog**

- [How to Measure Quality when Training Machine Learning Model](https://hackernoon.com/how-to-measure-quality-when-training-machine-learning-models-cc9196dd377a)

---

from [[_3_adding-non-linearity]]

[//begin]: # "Autogenerated link references for markdown compatibility"
[_3_adding-non-linearity]: ../_3_adding-non-linearity.md "♒️ NON-LINEARITY"
[//end]: # "Autogenerated link references"
