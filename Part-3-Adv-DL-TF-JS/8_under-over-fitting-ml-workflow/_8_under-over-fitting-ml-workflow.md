# ðŸ’§ Under Over Fitting ML Workflow

## [**Chapter 8.** Underfitting, overfitting, and the universal workflow of machine learning](https://livebook.manning.com/book/deep-learning-with-javascript/chapter-8/)

## _This chapter covers_

- Why it is important to visualize the model-training process and what the important things are to look for
- How to visualize and understand **underfitting** and overfitting
- The primary way of dealing with overfitting: **regularization**, and how to visualize its effect
- What the **universal workflow of machine learning is**, what steps it includes, and why it is an important recipe that guides all supervised machine-learning tasks

## Summary

- <b>`tfjs-vis`</b>
  - can aid the visualization of a machine-learning modelâ€™s training process in the browser. Specifically, we showed how `tfjs-vis` can be used to
  - Visualize the topology of TensorFlow.js models.
  - Plot loss and metrics curves during training.
  - Summarize weight distributions after training. We showed concrete examples of these visualization workflows.
- <b>Underfitting</b> and <b>overfitting</b>
  - are fundamental behaviors of machine-learning models and should be monitored and understood in every machine-learning problem. They can both be seen by comparing the loss curves from the training and validation sets during training. The built-in `tfvis.show.fitCallbacks()` method helps you visualize these curves in the browser with ease.
  - The universal workflow of machine learning is a list of common steps and best practices of different types of supervised learning tasks. It goes from deciding the nature of the problem and the requirements on the data to finding a model that sits nicely on the border between underfitting and overfitting.

---

## **Vocabulary**

- **`tfjs-viz`** -
- **data** -
- **training machine-learning models** -
- **bias variance tradeoff** - the more parameters you have relative to data, the more likely you are to pick a random solution as opposed to a good solution.
- **holdout sets** - take 85% of data for training and 15% for testing.
- **cross-validation** - check your performance on the training set and when that error goes up, you stop training.
- **constrain models** - make the number be as close to zero as possible in order to keep your data as close to each other.

<link rel="stylesheet" type="text/css" media="all" href="../../../assets/css/custom.css" />

---

from [[_part-3-adv-dl-ts-js]]

[//begin]: # "Autogenerated link references for markdown compatibility"
[_part-3-adv-dl-ts-js]: ../_part-3-adv-dl-ts-js.md "Part 3 Adv DL TS JS"
[//end]: # "Autogenerated link references"
