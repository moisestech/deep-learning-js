# ðŸ§¬ Attn Based Enc-Dec Model

## [**9.3.3.** Deep dive into the attention-based encoder-decoder model](https://livebook.manning.com/book/deep-learning-with-javascript/chapter-9/218)

---

### [**Figure 9.11.** Deep dive into the attention-based encoder-decoder model.](https://livebook.manning.com/book/deep-learning-with-javascript/chapter-9/ch09fig11)

<img src="../../../assets/figures/Figure_9-11.png">

---

## **Vocabulary**

- <b>deep-dive<b>
- <b>attention-based encode-decoder model</b>
- <b>`createModel()`</b>
- <b>`maskZero: true`</b>
- <b>`returnSequences: true`</b>
- <b>`GetLastTimestepLayer`</b>
- <b>symbolic tensor</b>
- <b>`encoderLast`</b>
- <b>softmax</b>
- <b>`decoderCombinedContext`</b>
- <b>`timeDistributed layer`</b>
- <b>`categorical cross-entropy`</b>
- <b>`argMax()`</b>
- <b>`dateTupleToMMMSpaceDDSpaceYY()`</b>

<link rel="stylesheet" type="text/css" media="all" href="../../../assets/css/custom.css" />

---

from [[_9-3-seq-to-seq-task-attn-mechanism]]

[//begin]: # "Autogenerated link references for markdown compatibility"
[_9-3-seq-to-seq-task-attn-mechanism]: _9-3-seq-to-seq-task-attn-mechanism.md "ðŸ§¬ Seq-to-seq Attn Mechanism"
[//end]: # "Autogenerated link references"
