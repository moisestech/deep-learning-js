# üíä 12 TESTING OPTIM

## [**Chapter 12.** Testing, optimizing, and deploying models]()

## Sub-Chapters

- **12.1.** Testing TensorFlow.js models
- **12.2.** Model optimization
- **12.3.** Deploying TensorFlow.js models on various platforms and environments

## This Chapter Covers

- The importance of and practical guidelines for testing and monitoring machine-learning code.
- How to optimize models trained in TensorFlow.js or converted to TensorFlow.js for faster loading and inference.
- How to deploy TensorFlow.js models to various platforms and environments, ranging from browser extensions to mobile apps, and from desktop apps to single-board computers.

---

## Summary

- Good engineering discipline around testing is as important to your machine-learning code as it is to your non-machine-learning code. However, avoid the temptation to focus strongly on ‚Äúspecial‚Äù examples or make assertions on ‚Äúgolden‚Äù model predictions. Instead, rely on testing the fundamental properties of your model, such as its input and output specifications. Furthermore, remember that all the data-preprocessing code before your machine-learning system is just ‚Äúnormal‚Äù code and should be tested accordingly.
- Optimizing the speed of downloading and inference is an important factor to the success of client-side deployment of TensorFlow.js models. Using the post-training weight quantization feature of the tensorflowjs_converter binary, you can reduce the total size of a model, in some cases without observable loss of inference accuracy. The graph-model conversion feature of tensorflowjs_converter helps to speed up model inference through graph transformations such as op fusion. You are highly encouraged to test and employ both model-optimization techniques when deploying your TensorFlow.js models to production.
- A trained, optimized model is not the end of the story for your machine-learning application. You must find some way to integrate it with an actual product. The most common way for TensorFlow.js applications to be deployed is within web pages, but this is just one of a wide variety of deployment scenarios, each with its own strengths. TensorFlow.js models can run as browser extensions, within native mobile apps, as native desktop applications, and even on single-board hardware like the Raspberry Pi.

---

## **Vocabulary**

- 

---
from [[_part-4-summary]]

[//begin]: # "Autogenerated link references for markdown compatibility"
[_part-4-summary]: ../_part-4-summary.md "Part 4 Summary"
[//end]: # "Autogenerated link references"